# Step 1: Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve
from imblearn.combine import SMOTETomek

# Step 2: Load the dataset
url = 'C:/Users/DEBMALYA/OneDrive/Desktop/New Microsoft Excel Worksheet.csv'  # Replace with your file path
df = pd.read_csv(url)

# Step 3: Data exploration and preprocessing
print(df.head())
print(df.describe())

# Step 4: Data preparation
# Remove unnecessary columns
df = df.drop(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'first', 'last', 'street','city', 'state', 'zip', 'lat', 'long', 'dob', 'trans_num', 'unix_time','merch_lat', 'merch_long'], axis=1)

# Check for remaining categorical columns and missing values
print(df.isnull().sum())
print(df.dtypes)

# Step 5: Encode categorical variables
# For 'category' and 'job', we'll use one-hot encoding
df = pd.get_dummies(df, columns=['category', 'job'], drop_first=True)

# Encode gender as a binary variable (1 for 'M', 0 for 'F')
df['gender'] = df['gender'].apply(lambda x: 1 if x == 'M' else 0)

# Step 6: Separate features and target
X = df.drop('is_fraud', axis=1)
y = df['is_fraud']

# Step 7: Handle class imbalance using SMOTETomek (with adjusted k_neighbors)
# Check class distribution before resampling
print("Class distribution before resampling:\n", y.value_counts())

# Adjust k_neighbors for SMOTETomek based on class distribution
smote_tomek = SMOTETomek(smote=dict(k_neighbors=1))  # Adjust k_neighbors as needed

# Perform resampling
X_resampled, y_resampled = smote_tomek.fit_resample(X, y)

# Check class distribution after resampling
print("Class distribution after resampling:\n", pd.Series(y_resampled).value_counts())

# Step 8: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)

# Step 9: Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 10: Training models
# Logistic Regression
log_reg = LogisticRegression()
log_reg.fit(X_train_scaled, y_train)
y_pred_log = log_reg.predict(X_test_scaled)

# Decision Tree
tree_clf = DecisionTreeClassifier(random_state=42)
tree_clf.fit(X_train, y_train)
y_pred_tree = tree_clf.predict(X_test)

# Random Forest
rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
rf_clf.fit(X_train, y_train)
y_pred_rf = rf_clf.predict(X_test)

# Step 11: Model evaluation
# Function to evaluate the model performance
def evaluate_model(y_test, y_pred):
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("AUC-ROC:", roc_auc_score(y_test, y_pred))

# Evaluate Logistic Regression
print("\nLogistic Regression Performance")
evaluate_model(y_test, y_pred_log)

# Evaluate Decision Tree
print("\nDecision Tree Performance")
evaluate_model(y_test, y_pred_tree)

# Evaluate Random Forest
print("\nRandom Forest Performance")
evaluate_model(y_test, y_pred_rf)

# Step 12: Visualize the ROC curve
# ROC curve for Logistic Regression
fpr_log, tpr_log, _ = roc_curve(y_test, log_reg.predict_proba(X_test_scaled)[:,1])
# ROC curve for Decision Tree
fpr_tree, tpr_tree, _ = roc_curve(y_test, tree_clf.predict_proba(X_test)[:,1])
# ROC curve for Random Forest
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_clf.predict_proba(X_test)[:,1])

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr_log, tpr_log, label="Logistic Regression")
plt.plot(fpr_tree, tpr_tree, label="Decision Tree")
plt.plot(fpr_rf, tpr_rf, label="Random Forest")
plt.plot([0,1], [0,1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()
